name: Deploy Backend and Update Frontend Monitor

on:
  workflow_run:
    workflows: ["CI Tests & Deployment"]
    types:
      - completed
    branches: [develop, main]

jobs:
  deploy:
    name: Deploy to GCP
    # Only run if the CI workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.ref }}

      # Set environment-specific variables
      - name: Set Environment Specifics
        id: set_env
        run: |
          if [[ "${{ github.event.workflow_run.head_branch || github.ref_name }}" == "develop" ]]; then
            echo "ENVIRONMENT=dev" >> $GITHUB_ENV
            echo "GCP_PROJECT_ID=${{ secrets.DEV_GCP_PROJECT_ID }}" >> $GITHUB_ENV
            echo "GCP_ZONE=${{ secrets.DEV_GCP_ZONE }}" >> $GITHUB_ENV
            echo "NAMING_PREFIX=${{ secrets.DEV_NAMING_PREFIX }}" >> $GITHUB_ENV
            echo "WORKLOAD_IDENTITY_PROVIDER=${{ secrets.DEV_WORKLOAD_IDENTITY_PROVIDER }}" >> $GITHUB_ENV
            echo "CICD_SERVICE_ACCOUNT=${{ secrets.DEV_CICD_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "ARTIFACT_REGISTRY_REPO_NAME=${{ secrets.DEV_ARTIFACT_REGISTRY_REPO_NAME }}" >> $GITHUB_ENV
            echo "WORKER_SERVICE_ACCOUNT_EMAIL=${{ secrets.DEV_WORKER_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "API_SERVICE_ACCOUNT_EMAIL=${{ secrets.DEV_API_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "WORKER_MIN_INSTANCES=${{ secrets.DEV_WORKER_MIN_INSTANCES || 0 }}" >> $GITHUB_ENV
            echo "WORKER_MAX_INSTANCES=${{ secrets.DEV_WORKER_MAX_INSTANCES || 5 }}" >> $GITHUB_ENV
            echo "FRONTEND_UPTIME_CHECK_ID=${{ secrets.DEV_FRONTEND_UPTIME_CHECK_CONFIG_ID }}" >> $GITHUB_ENV
            echo "VERCEL_PROJECT_ID=${{ secrets.DEV_VERCEL_PROJECT_ID }}" >> $GITHUB_ENV
            echo "FRONTEND_ALERT_POLICY_ID=${{ secrets.DEV_FRONTEND_ALERT_POLICY_ID }}" >> $GITHUB_ENV
            echo "ALERT_NOTIFICATION_CHANNEL_FULL_ID=${{ secrets.DEV_ALERT_NOTIFICATION_CHANNEL_FULL_ID }}" >> $GITHUB_ENV
            echo "FRONTEND_STARTUP_ALERT_DELAY=${{ secrets.DEV_FRONTEND_STARTUP_ALERT_DELAY || '2100s' }}" >> $GITHUB_ENV
            echo "ALERT_ALIGNMENT_PERIOD=${{ secrets.DEV_ALERT_ALIGNMENT_PERIOD || '300s' }}" >> $GITHUB_ENV
          elif [[ "${{ github.event.workflow_run.head_branch || github.ref_name }}" == "main" ]]; then
            echo "ENVIRONMENT=prod" >> $GITHUB_ENV
            echo "GCP_PROJECT_ID=${{ secrets.PROD_GCP_PROJECT_ID }}" >> $GITHUB_ENV
            echo "GCP_ZONE=${{ secrets.PROD_GCP_ZONE }}" >> $GITHUB_ENV
            echo "NAMING_PREFIX=${{ secrets.PROD_NAMING_PREFIX }}" >> $GITHUB_ENV
            echo "WORKLOAD_IDENTITY_PROVIDER=${{ secrets.PROD_WORKLOAD_IDENTITY_PROVIDER }}" >> $GITHUB_ENV
            echo "CICD_SERVICE_ACCOUNT=${{ secrets.PROD_CICD_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "ARTIFACT_REGISTRY_REPO_NAME=${{ secrets.PROD_ARTIFACT_REGISTRY_REPO_NAME }}" >> $GITHUB_ENV
            echo "WORKER_SERVICE_ACCOUNT_EMAIL=${{ secrets.PROD_WORKER_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "API_SERVICE_ACCOUNT_EMAIL=${{ secrets.PROD_API_SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
            echo "WORKER_MIN_INSTANCES=${{ secrets.PROD_WORKER_MIN_INSTANCES || 0 }}" >> $GITHUB_ENV
            echo "WORKER_MAX_INSTANCES=${{ secrets.PROD_WORKER_MAX_INSTANCES || 5 }}" >> $GITHUB_ENV
            echo "FRONTEND_UPTIME_CHECK_ID=${{ secrets.PROD_FRONTEND_UPTIME_CHECK_CONFIG_ID }}" >> $GITHUB_ENV
            echo "VERCEL_PROJECT_ID=${{ secrets.PROD_VERCEL_PROJECT_ID }}" >> $GITHUB_ENV
            echo "FRONTEND_ALERT_POLICY_ID=${{ secrets.PROD_FRONTEND_ALERT_POLICY_ID }}" >> $GITHUB_ENV
            echo "ALERT_NOTIFICATION_CHANNEL_FULL_ID=${{ secrets.PROD_ALERT_NOTIFICATION_CHANNEL_FULL_ID }}" >> $GITHUB_ENV
            echo "FRONTEND_STARTUP_ALERT_DELAY=${{ secrets.PROD_FRONTEND_STARTUP_ALERT_DELAY || '2100s' }}" >> $GITHUB_ENV
            echo "ALERT_ALIGNMENT_PERIOD=${{ secrets.PROD_ALERT_ALIGNMENT_PERIOD || '300s' }}" >> $GITHUB_ENV
          else
            echo "Branch is not develop or main, skipping deployment."
            exit 0
          fi
          echo "REGION=${{ secrets.GCP_REGION }}" >> $GITHUB_ENV

      # Authenticate with the appropriate environment credentials
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        id: gcloud_auth
        with:
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ env.CICD_SERVICE_ACCOUNT }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18

      - name: Install dependencies
        run: |
          npm install -g vercel
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Deploy Cloud Function Worker
        run: |
          FUNCTION_NAME="${{ env.NAMING_PREFIX }}-worker-${{ env.ENVIRONMENT }}"
          TASKS_TOPIC_NAME="${{ env.NAMING_PREFIX }}-tasks-${{ env.ENVIRONMENT }}"

          echo "Deploying Function: $FUNCTION_NAME"
          echo "Trigger Topic: $TASKS_TOPIC_NAME"
          echo "Service Account: ${{ env.WORKER_SERVICE_ACCOUNT_EMAIL }}"

          # Construct --set-secrets argument dynamically
          SECRETS_ARG=""
          SECRETS_ARG+="CONCEPT_SUPABASE_URL=${{ env.NAMING_PREFIX }}-supabase-url-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_SUPABASE_KEY=${{ env.NAMING_PREFIX }}-supabase-key-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_SUPABASE_SERVICE_ROLE=${{ env.NAMING_PREFIX }}-supabase-service-role-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_SUPABASE_JWT_SECRET=${{ env.NAMING_PREFIX }}-supabase-jwt-secret-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_JIGSAWSTACK_API_KEY=${{ env.NAMING_PREFIX }}-jigsawstack-api-key-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_UPSTASH_REDIS_ENDPOINT=${{ env.NAMING_PREFIX }}-redis-endpoint-${{ env.ENVIRONMENT }}:latest,"
          SECRETS_ARG+="CONCEPT_UPSTASH_REDIS_PASSWORD=${{ env.NAMING_PREFIX }}-redis-password-${{ env.ENVIRONMENT }}:latest"

          # Deploy the function using the 'backend' directory as source with the shim main.py
          gcloud functions deploy "$FUNCTION_NAME" \
            --gen2 \
            --region="${{ env.REGION }}" \
            --project="${{ env.GCP_PROJECT_ID }}" \
            --runtime=python311 \
            --entry-point=handle_pubsub \
            --run-service-account="${{ env.WORKER_SERVICE_ACCOUNT_EMAIL }}" \
            --trigger-topic="$TASKS_TOPIC_NAME" \
            --timeout=540s \
            --memory=2048Mi \
            --min-instances=${{ env.WORKER_MIN_INSTANCES }} \
            --max-instances=${{ env.WORKER_MAX_INSTANCES }} \
            --set-env-vars="ENVIRONMENT=${{ env.ENVIRONMENT }},GCP_PROJECT_ID=${{ env.GCP_PROJECT_ID }},CONCEPT_STORAGE_BUCKET_CONCEPT=concept-images-${{ env.ENVIRONMENT }},CONCEPT_STORAGE_BUCKET_PALETTE=palette-images-${{ env.ENVIRONMENT }},CONCEPT_DB_TABLE_TASKS=tasks_${{ env.ENVIRONMENT }},CONCEPT_DB_TABLE_CONCEPTS=concepts_${{ env.ENVIRONMENT }},CONCEPT_DB_TABLE_PALETTES=color_variations_${{ env.ENVIRONMENT }},CONCEPT_LOG_LEVEL=$([[ "${{ env.ENVIRONMENT }}" == "prod" ]] && echo "INFO" || echo "DEBUG"),CONCEPT_UPSTASH_REDIS_PORT=6379" \
            --set-secrets="$SECRETS_ARG" \
            --source="./backend" \
            --allow-unauthenticated \
            --quiet

      - name: Deploy API to Compute Engine MIG (Rolling Update)
        run: |
          IMAGE_URL="${{ env.REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT_ID }}/${{ env.ARTIFACT_REGISTRY_REPO_NAME }}/concept-api-${{ env.ENVIRONMENT }}:${{ github.sha }}"
          # Use a shorter hash (first 8 characters) and add timestamp for uniqueness
          SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-8)
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          TEMPLATE_NAME="${{ env.NAMING_PREFIX }}-api-tpl-${SHORT_SHA}-${TIMESTAMP}"
          MIG_NAME="${{ env.NAMING_PREFIX }}-api-igm-${{ env.ENVIRONMENT }}"

          echo "Target Template Name: $TEMPLATE_NAME"
          echo "MIG Name: $MIG_NAME"
          echo "New Image: $IMAGE_URL"

          # Get the static IP that Terraform has created for this environment
          STATIC_IP_NAME="${{ env.NAMING_PREFIX }}-api-ip-${{ env.ENVIRONMENT }}"
          STATIC_IP=$(gcloud compute addresses describe "$STATIC_IP_NAME" \
            --project="${{ env.GCP_PROJECT_ID }}" \
            --region="${{ env.REGION }}" \
            --format="get(address)")

          echo "Using static IP: $STATIC_IP"

          echo "Creating new instance template '$TEMPLATE_NAME'..."
          # Always create a new instance template with the required configuration
          gcloud compute instance-templates create "$TEMPLATE_NAME" \
            --project="${{ env.GCP_PROJECT_ID }}" \
            --region="${{ env.REGION }}" \
            --machine-type=e2-micro \
            --network-tier=$([[ "${{ env.ENVIRONMENT }}" == "prod" ]] && echo "PREMIUM" || echo "STANDARD") \
            --maintenance-policy=MIGRATE \
            --provisioning-model=STANDARD \
            --service-account="${{ env.API_SERVICE_ACCOUNT_EMAIL }}" \
            --scopes=https://www.googleapis.com/auth/cloud-platform \
            --tags=http-server,https-server,concept-api,${{ env.NAMING_PREFIX }}-api-vm-${{ env.ENVIRONMENT }} \
            --create-disk=auto-delete=yes,boot=yes,device-name=boot,image-family=debian-11,image-project=debian-cloud,mode=rw,size=10,type=pd-balanced \
            --subnet=projects/${{ env.GCP_PROJECT_ID }}/regions/${{ env.REGION }}/subnetworks/default \
            --address="$STATIC_IP" \
            --metadata=startup-script-url=gs://${{ env.NAMING_PREFIX }}-assets-${{ env.ENVIRONMENT }}/startup-scripts/api-startup.sh,environment=${{ env.ENVIRONMENT }},naming_prefix=${{ env.NAMING_PREFIX }},region=${{ env.REGION }},docker-image="$IMAGE_URL" \
            --description="Template for Concept API instances (${{ github.sha }}) created at $(date)"

          # Check the exit code of the create command
          if [ $? -ne 0 ]; then
            echo "Error: Failed to create instance template '$TEMPLATE_NAME'."
            exit 1
          fi
          echo "Instance template '$TEMPLATE_NAME' created successfully."

          # First update the template in the MIG
          echo "Setting new instance template for MIG"
          gcloud compute instance-groups managed set-instance-template "$MIG_NAME" \
            --template="$TEMPLATE_NAME" \
            --zone="${{ env.GCP_ZONE }}" \
            --project="${{ env.GCP_PROJECT_ID }}"

          # Get the current VM instances and note them down
          echo "Getting current VM instances from the managed instance group"
          EXISTING_INSTANCES=$(gcloud compute instance-groups managed list-instances "$MIG_NAME" \
            --zone="${{ env.GCP_ZONE }}" \
            --project="${{ env.GCP_PROJECT_ID }}" \
            --format="value(name)")

          if [ -n "$EXISTING_INSTANCES" ]; then
            echo "Found existing instances: $EXISTING_INSTANCES"

            # Start the replacement operation
            echo "Replacing all instances with new template"
            gcloud compute instance-groups managed rolling-action replace "$MIG_NAME" \
              --max-unavailable=100% \
              --replacement-method=recreate \
              --zone="${{ env.GCP_ZONE }}" \
              --project="${{ env.GCP_PROJECT_ID }}"

            # Wait for the instances to be stable
            echo "Waiting for instance group to become stable"
            gcloud compute instance-groups managed wait-until \
              --stable \
              --zone="${{ env.GCP_ZONE }}" \
              --project="${{ env.GCP_PROJECT_ID }}" \
              --timeout=300 \
              "$MIG_NAME"

            echo "Instance group is now stable"

            # Get the new VM instances
            NEW_INSTANCES=$(gcloud compute instance-groups managed list-instances "$MIG_NAME" \
              --zone="${{ env.GCP_ZONE }}" \
              --project="${{ env.GCP_PROJECT_ID }}" \
              --format="value(name)")

            echo "New instances after replacement: $NEW_INSTANCES"

            # Force a restart of each new instance to ensure startup script runs with new image
            if [ -n "$NEW_INSTANCES" ]; then
              for INSTANCE in $NEW_INSTANCES; do
                echo "Ensuring instance $INSTANCE is using the new template and image"
                echo "Restarting instance $INSTANCE to force startup script execution"
                gcloud compute instances reset "$INSTANCE" \
                  --zone="${{ env.GCP_ZONE }}" \
                  --project="${{ env.GCP_PROJECT_ID }}" || echo "Warning: Failed to reset instance $INSTANCE"

                # Wait a bit for the restart to complete
                echo "Waiting 30 seconds for instance restart..."
                sleep 30
              done
            fi
          else
            echo "No VM instances found to replace"
          fi

          # Clean up old templates, keeping only the latest 10
          echo "Cleaning up old instance templates, keeping the latest 10"
          OLD_TEMPLATES=$(gcloud compute instance-templates list \
            --filter="name ~ '${{ env.NAMING_PREFIX }}-api-tpl-'" \
            --project="${{ env.GCP_PROJECT_ID }}" \
            --sort-by=~creationTimestamp \
            --format="value(name)" \
            | tail -n +11)

          if [ -n "$OLD_TEMPLATES" ]; then
            echo "Found old templates to delete:"
            echo "$OLD_TEMPLATES"
            for OLD_TEMPLATE in $OLD_TEMPLATES; do
              echo "Deleting old template: $OLD_TEMPLATE"
              gcloud compute instance-templates delete "$OLD_TEMPLATE" \
                --project="${{ env.GCP_PROJECT_ID }}" \
                --quiet || echo "Warning: Failed to delete template $OLD_TEMPLATE"
            done
          else
            echo "No old templates to clean up (keeping the latest 10)"
          fi

      - name: Get Latest Vercel Deployment URL
        id: get_vercel_url
        if: env.ENVIRONMENT == 'dev' || env.ENVIRONMENT == 'prod'
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          PROJECT_ID_VERCEL: ${{ env.VERCEL_PROJECT_ID }}
          # Pass the commit SHA from the parent workflow that triggered this one
          COMMIT_SHA_FROM_PARENT_WORKFLOW: ${{ github.event.workflow_run.head_sha }}
          BRANCH_NAME_FROM_PARENT_WORKFLOW: ${{ github.event.workflow_run.head_branch }}
        run: |
          echo "Fetching deployment URL for Vercel Project ID: $PROJECT_ID_VERCEL"
          echo "Branch: $BRANCH_NAME_FROM_PARENT_WORKFLOW, Commit: $COMMIT_SHA_FROM_PARENT_WORKFLOW"

          SCOPE_ARG=""
          if [[ -n "$VERCEL_ORG_ID" ]]; then
            SCOPE_ARG="--scope $VERCEL_ORG_ID"
          fi

          # Instead of using vercel CLI commands with json output, use the Vercel REST API
          echo "Fetching deployments from Vercel API..."

          # Create Vercel config directory and credentials file
          mkdir -p ~/.vercel
          echo "{\"token\":\"$VERCEL_TOKEN\"}" > ~/.vercel/credentials.json

          # Use vercel CLI to get the project name
          PROJECT_NAME=$(vercel project ls $SCOPE_ARG | grep "$PROJECT_ID_VERCEL" | awk '{print $1}')
          echo "Project name: $PROJECT_NAME"

          if [[ -z "$PROJECT_NAME" ]]; then
            echo "Could not determine project name from project ID. Using direct API calls."

            # Use curl with Vercel API to get deployment information
            API_URL="https://api.vercel.com/v6/deployments"
            if [[ -n "$VERCEL_ORG_ID" ]]; then
              API_URL="${API_URL}?teamId=${VERCEL_ORG_ID}"
            fi

            DEPLOYMENTS_OUTPUT=$(curl -s -H "Authorization: Bearer $VERCEL_TOKEN" "$API_URL")
            LATEST_DEPLOYMENT_URL=""

            # If this is the main branch, look for production deployments
            if [[ "$BRANCH_NAME_FROM_PARENT_WORKFLOW" == "main" ]]; then
              echo "Looking for production deployments for main branch..."
              LATEST_DEPLOYMENT_URL=$(echo "$DEPLOYMENTS_OUTPUT" | jq -r '.deployments[] | select(.target == "production") | .url' | head -n 1)

              # If we found a production URL, it might be an alias
              if [[ -n "$LATEST_DEPLOYMENT_URL" && "$LATEST_DEPLOYMENT_URL" != "null" ]]; then
                # Check if this is an alias domain
                DOMAINS_OUTPUT=$(curl -s -H "Authorization: Bearer $VERCEL_TOKEN" "https://api.vercel.com/v9/projects/$PROJECT_ID_VERCEL/domains")
                PROD_DOMAIN=$(echo "$DOMAINS_OUTPUT" | jq -r '.domains[] | select(.apexName != null) | .name' | head -n 1)

                if [[ -n "$PROD_DOMAIN" && "$PROD_DOMAIN" != "null" ]]; then
                  LATEST_DEPLOYMENT_URL="https://$PROD_DOMAIN"
                  echo "Found production domain: $LATEST_DEPLOYMENT_URL"
                else
                  LATEST_DEPLOYMENT_URL="https://$LATEST_DEPLOYMENT_URL"
                  echo "Using deployment URL: $LATEST_DEPLOYMENT_URL"
                fi
              fi
            fi

            # If we still don't have a URL, try to get the most recent deployment
            if [[ -z "$LATEST_DEPLOYMENT_URL" || "$LATEST_DEPLOYMENT_URL" == "null" ]]; then
              echo "Falling back to most recent deployment..."
              LATEST_DEPLOYMENT_URL=$(echo "$DEPLOYMENTS_OUTPUT" | jq -r '.deployments[0].url' | head -n 1)

              if [[ -n "$LATEST_DEPLOYMENT_URL" && "$LATEST_DEPLOYMENT_URL" != "null" ]]; then
                LATEST_DEPLOYMENT_URL="https://$LATEST_DEPLOYMENT_URL"
              fi
            fi

            DEPLOY_URL="$LATEST_DEPLOYMENT_URL"
          else
            # Use the vercel inspect command on the project name to get the URL
            echo "Using vercel inspect to get deployment URL..."

            # For production/main branch
            if [[ "$BRANCH_NAME_FROM_PARENT_WORKFLOW" == "main" ]]; then
              # Try to get info about the current production deployment
              INSPECT_OUTPUT=$(vercel inspect "$PROJECT_NAME" $SCOPE_ARG)

              # Extract URL from the output using grep and awk
              DEPLOY_URL=$(echo "$INSPECT_OUTPUT" | grep -A 1 "Production URL" | tail -n 1 | awk '{print $NF}')

              # If no production URL is found, try getting the latest deployment
              if [[ -z "$DEPLOY_URL" || "$DEPLOY_URL" == "null" ]]; then
                echo "No production URL found, getting latest deployment..."
                LATEST_OUTPUT=$(vercel ls "$PROJECT_NAME" $SCOPE_ARG | grep -v 'Production\|Name\|To deploy\|Deployments' | head -n 1)
                LATEST_ID=$(echo "$LATEST_OUTPUT" | awk '{print $1}')

                if [[ -n "$LATEST_ID" && "$LATEST_ID" != "null" ]]; then
                  DEPLOY_INSPECT=$(vercel inspect "$LATEST_ID" $SCOPE_ARG)
                  DEPLOY_URL=$(echo "$DEPLOY_INSPECT" | grep "URL:" | head -n 1 | awk '{print $NF}')
                  DEPLOY_URL="https://$DEPLOY_URL"
                fi
              fi
            else
              # For non-production branches, get the most recent deployment
              LATEST_OUTPUT=$(vercel ls "$PROJECT_NAME" $SCOPE_ARG | grep -v 'Production\|Name\|To deploy\|Deployments' | head -n 1)
              LATEST_ID=$(echo "$LATEST_OUTPUT" | awk '{print $1}')

              if [[ -n "$LATEST_ID" && "$LATEST_ID" != "null" ]]; then
                DEPLOY_INSPECT=$(vercel inspect "$LATEST_ID" $SCOPE_ARG)
                DEPLOY_URL=$(echo "$DEPLOY_INSPECT" | grep "URL:" | head -n 1 | awk '{print $NF}')
                DEPLOY_URL="https://$DEPLOY_URL"
              fi
            fi
          fi

          # Validate the URL
          if [[ -z "$DEPLOY_URL" || "$DEPLOY_URL" == "null" ]]; then
            echo "Error: Could not determine a valid deployment URL."

            # Final fallback - hardcode the URL based on project name pattern
            if [[ "$BRANCH_NAME_FROM_PARENT_WORKFLOW" == "main" && -n "$PROJECT_NAME" ]]; then
              DEPLOY_URL="https://$PROJECT_NAME.vercel.app"
              echo "Using fallback URL based on project name: $DEPLOY_URL"
            else
              exit 1
            fi
          fi

          echo "Final Vercel Deployment URL for Monitoring: $DEPLOY_URL"
          echo "VERCEL_DEPLOYMENT_URL_FOR_MONITORING=$DEPLOY_URL" >> $GITHUB_ENV
          echo "::set-output name=url::$DEPLOY_URL"

      - name: Apply/Update Frontend Monitoring Resources
        if: env.FRONTEND_UPTIME_CHECK_ID != '' && steps.get_vercel_url.outputs.url != '' && env.ENVIRONMENT == 'dev' || env.ENVIRONMENT == 'prod'
        env:
          TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET_NAME }}
          VERCEL_URL: ${{ steps.get_vercel_url.outputs.url }}
          ALERT_EMAIL_ADDRESS: ${{ secrets.ALERT_EMAIL_ADDRESS }}
        run: |
          echo "Applying frontend monitoring configuration with actual Vercel URL"
          echo "Vercel URL for monitoring: $VERCEL_URL"

          # Strip protocol and path from Vercel URL (required for uptime checks)
          # Remove https:// or http:// prefix
          CLEAN_VERCEL_HOST=$(echo "$VERCEL_URL" | sed -E 's~^https?://~~')
          # Remove any path component (anything after the first slash)
          CLEAN_VERCEL_HOST=$(echo "$CLEAN_VERCEL_HOST" | sed -E 's~/.*$~~')
          echo "Cleaned hostname for uptime check: $CLEAN_VERCEL_HOST"

          # Additional debugging
          echo "Current directory: $(pwd)"
          echo "Contents of terraform directory:"
          ls -la terraform/
          echo "Contents of environments directory (if it exists):"
          ls -la terraform/environments/ || echo "Environments directory not found"

          # Initialize Terraform using the shared remote backend
          terraform -chdir=terraform init -reconfigure \
            -backend-config="bucket=$TF_STATE_BUCKET"

          # Select the appropriate workspace
          terraform -chdir=terraform workspace select "${{ env.ENVIRONMENT }}"

          # Check for required variables
          echo "Checking required variables..."
          terraform -chdir=terraform providers

          # Create a temporary tfvars file with just what we need for this operation
          echo "Creating temporary tfvars file..."
          cat > terraform/temp_frontend_monitoring.tfvars <<EOF
          project_id = "${{ env.GCP_PROJECT_ID }}"
          environment = "${{ env.ENVIRONMENT }}"
          naming_prefix = "${{ env.NAMING_PREFIX }}"
          frontend_hostname = "$CLEAN_VERCEL_HOST"
          alert_email_address = "$ALERT_EMAIL_ADDRESS"
          region = "${{ env.REGION }}"
          zone = "${{ env.GCP_ZONE }}"
          terraform_state_bucket_name = "$TF_STATE_BUCKET"
          manual_tf_state_bucket_name = "$TF_STATE_BUCKET"
          github_repo = ""
          terraform_runner_user_emails = []
          terraform_cicd_sa_email = ""
          allow_ssh_ips = []
          EOF

          echo "Content of temporary tfvars file:"
          cat terraform/temp_frontend_monitoring.tfvars

          # Try to apply with the temporary tfvars file
          echo "Proceeding with terraform apply using temporary tfvars file..."
          terraform -chdir=terraform apply -auto-approve \
            -var-file="temp_frontend_monitoring.tfvars" \
            -target=google_monitoring_uptime_check_config.frontend_availability \
            -target=google_monitoring_alert_policy.frontend_availability_failure_alert

          echo "Frontend monitoring resources updated successfully to target: $CLEAN_VERCEL_HOST"

          # Clean up temporary file
          rm -f terraform/temp_frontend_monitoring.tfvars
