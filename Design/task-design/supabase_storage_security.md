# Supabase Storage Security Design Specification

## Problem Statement

The current implementation of the Concept Visualizer application uses public Supabase storage buckets for storing generated images. While the application organizes images by session ID in separate folders, this approach has several potential security concerns:

1. Anyone with knowledge of the URL pattern can potentially access any image by guessing session IDs
2. There's no verification that the requester of an image is the owner of that session
3. Images remain accessible indefinitely, even after sessions are no longer active
4. There's no mechanism to prevent automated scraping or enumeration of images

## Goals

1. Improve security of stored images while maintaining the session-based, no-registration user model
2. Prevent unauthorized access to images generated by other users
3. Limit potential for abuse (scraping, enumeration)
4. Maintain or improve performance and user experience
5. Implement with minimal changes to the existing architecture

## Implementation Options

### Option 1: Row Level Security (RLS) with Session Authentication

This approach would use Supabase's RLS policies to restrict access to images based on session IDs.

**Pros:**

- Most secure approach
- Leverages Supabase's built-in security features
- Can be implemented entirely on the database side

**Cons:**

- Requires significant changes to the authentication flow
- More complex implementation
- May impact performance with additional authentication checks

### Option 2: Server-side Proxy for Image Serving

This approach would make storage buckets private and serve images through a backend API endpoint that validates the requesting session.

**Pros:**

- High security - complete control over access
- Simple to understand and implement
- Works well with existing session cookie mechanism

**Cons:**

- Additional load on backend server
- Potential performance impact for image loading
- Bandwidth used twice (once from Supabase to server, once from server to client)

### Option 3: Signed URLs with Short Expiration

This approach maintains public buckets but only serves short-lived signed URLs that expire after a set time period.

**Pros:**

- Good balance of security and performance
- Relatively easy to implement
- Minimal changes to existing architecture
- Leverages Supabase's built-in capabilities
- No additional server load for serving images

**Cons:**

- URLs could be shared during their validity period
- May require refreshing URLs for long user sessions
- Some management overhead for URL regeneration

## Recommended Approach

After evaluating the options, **Option 3: Signed URLs with Short Expiration** provides the best balance of security and implementation simplicity for the current architecture. This approach allows us to maintain the current session-based model without requiring user registration while significantly improving security.

## Implementation Details

### 1. Backend Changes

#### Update Supabase Storage Service

Modify the existing storage service to use signed URLs instead of public URLs:

```python
# backend/app/services/image/storage.py
async def get_public_url(self, image_path: str, is_palette: bool = False, expiry_seconds: int = 3600) -> str:
    """
    Get a signed URL for an image in storage with an expiration time.

    Args:
        image_path: Path to the image in storage
        is_palette: Whether this is a palette image (uses palette-images bucket)
        expiry_seconds: Time in seconds until the URL expires (default: 1 hour)

    Returns:
        Signed URL for the image with expiration

    Raises:
        ImageStorageError: If URL generation fails
    """
    try:
        # Select the appropriate bucket
        bucket_name = self.palette_bucket if is_palette else self.concept_bucket

        # Get a signed URL with expiration
        if hasattr(self.supabase, 'client') and hasattr(self.supabase.client, 'storage'):
            response = self.supabase.client.storage.from_(bucket_name).create_signed_url(
                path=image_path,
                expires_in=expiry_seconds
            )
            return response['signedURL']
        else:
            response = self.supabase.storage.from_(bucket_name).create_signed_url(
                path=image_path,
                expires_in=expiry_seconds
            )
            return response['signedURL']

    except Exception as e:
        error_msg = f"Failed to get signed URL for image {image_path}: {str(e)}"
        self.logger.error(error_msg)
        raise ImageStorageError(error_msg)
```

#### Update Image Service

Modify the image service to use the new signed URL functionality:

```python
# backend/app/services/image/service.py
def get_image_url(self, image_path: str, bucket_name: str, expiry_seconds: int = 3600) -> str:
    """
    Get a signed URL for an image in storage with an expiration time.

    Args:
        image_path: Path to the image in storage
        bucket_name: Name of the bucket (e.g., "concept-images" or "palette-images")
        expiry_seconds: Time in seconds until the URL expires (default: 1 hour)

    Returns:
        Signed URL for the image

    Raises:
        ImageError: If URL generation fails
    """
    try:
        # Determine if this is a palette image based on the bucket name
        is_palette = bucket_name == settings.STORAGE_BUCKET_PALETTE

        # Use the storage service to get the URL
        return self.storage.get_public_url(
            image_path=image_path,
            is_palette=is_palette,
            expiry_seconds=expiry_seconds
        )

    except Exception as e:
        self.logger.error(f"Error getting image URL: {str(e)}")
        raise ImageError(f"Failed to get image URL: {str(e)}")
```

#### Update API Response Models

Ensure your API response models include the URL expiration time so the frontend knows when to request new URLs:

```python
# backend/app/models/concept/response.py
class ImageResponse(BaseModel):
    url: str
    expires_at: int  # Unix timestamp when the URL expires
    path: str  # The storage path (used for requesting refreshed URLs)
```

#### Add URL Refresh Endpoint

Add an endpoint to refresh expired URLs:

```python
# backend/app/api/routes/concept/images.py
@router.get("/refresh-url/{image_path:path}", response_model=ImageResponse)
async def refresh_image_url(
    image_path: str,
    is_palette: bool = Query(False),
    session_service: SessionService = Depends(get_session_service),
    image_service: ImageService = Depends(get_image_service),
    session_id: Optional[str] = Cookie(None, alias="concept_session")
):
    """Refresh an expired image URL."""
    # Verify session
    valid_session_id, _ = await session_service.get_or_create_session(session_id)

    # Verify the image belongs to this session
    if not image_path.startswith(f"{valid_session_id}/"):
        raise HTTPException(status_code=403, detail="Not authorized to access this image")

    # Get a fresh signed URL
    bucket_name = settings.STORAGE_BUCKET_PALETTE if is_palette else settings.STORAGE_BUCKET_CONCEPT
    url = image_service.get_image_url(image_path, bucket_name)

    # Calculate expiration time (current time + expiry seconds)
    expires_at = int(time.time()) + 3600  # 1 hour from now

    return {
        "url": url,
        "expires_at": expires_at,
        "path": image_path
    }
```

### 2. Frontend Changes

#### Update API Client

Modify your frontend API client to handle URL expiration and refreshing:

```typescript
// frontend/src/services/imageService.ts
import apiClient from "./api";

interface ImageInfo {
  url: string;
  expiresAt: number;
  path: string;
}

const imageCache = new Map<string, ImageInfo>();

export const getImageUrl = async (
  path: string,
  isPalette: boolean = false,
): Promise<string> => {
  // Check if we have a cached non-expired URL
  const now = Math.floor(Date.now() / 1000);
  const cached = imageCache.get(path);

  if (cached && cached.expiresAt > now) {
    return cached.url;
  }

  // If expired or not cached, request a fresh URL
  try {
    const response = await apiClient.get(
      `/api/concept/images/refresh-url/${encodeURIComponent(path)}`,
      {
        params: { is_palette: isPalette },
      },
    );

    const imageInfo: ImageInfo = {
      url: response.data.url,
      expiresAt: response.data.expires_at,
      path: response.data.path,
    };

    // Cache the new URL
    imageCache.set(path, imageInfo);

    return imageInfo.url;
  } catch (error) {
    console.error("Error refreshing image URL:", error);
    // Return cached URL even if expired as fallback
    return cached?.url || "";
  }
};
```

#### Update Image Components

Update your image components to use the new URL service:

```tsx
// frontend/src/components/concept/ConceptImage.tsx
import React, { useState, useEffect } from "react";
import { getImageUrl } from "../../services/imageService";

interface ConceptImageProps {
  path: string;
  isPalette?: boolean;
  alt: string;
  className?: string;
}

const ConceptImage: React.FC<ConceptImageProps> = ({
  path,
  isPalette = false,
  alt,
  className,
}) => {
  const [imageUrl, setImageUrl] = useState<string>("");
  const [isLoading, setIsLoading] = useState<boolean>(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    const loadImage = async () => {
      if (!path) return;

      setIsLoading(true);
      try {
        const url = await getImageUrl(path, isPalette);
        setImageUrl(url);
        setError(null);
      } catch (err) {
        console.error("Error loading image:", err);
        setError("Failed to load image");
      } finally {
        setIsLoading(false);
      }
    };

    loadImage();

    // Set up a refresh interval for long-lived components (optional)
    const intervalId = setInterval(
      () => {
        loadImage();
      },
      30 * 60 * 1000,
    ); // Refresh every 30 minutes

    return () => clearInterval(intervalId);
  }, [path, isPalette]);

  if (isLoading) {
    return <div className="image-placeholder">Loading...</div>;
  }

  if (error) {
    return <div className="image-error">{error}</div>;
  }

  return <img src={imageUrl} alt={alt} className={className} />;
};

export default ConceptImage;
```

### 3. Supabase Configuration Changes

Update your Supabase storage bucket policies to slightly restrict access:

1. Navigate to Supabase Dashboard → Storage → Bucket Settings
2. For each bucket, remove any existing "Public read access" policy
3. Add a new policy with slightly restricted access:

```sql
-- RLS policy for concept-images and palette-images
CREATE POLICY "Allow access with valid session cookie"
ON storage.objects FOR SELECT
USING (bucket_id IN ('concept-images', 'palette-images') AND request.header('Cookie') IS NOT NULL);
```

This simple policy ensures that only requests with a Cookie header can access images, which helps prevent basic scraping.

## Testing Plan

1. **Unit Tests**:

   - Test URL generation and expiration logic
   - Test URL refresh functionality
   - Test session validation for image access

2. **Integration Tests**:

   - Verify image loading with signed URLs
   - Test URL refresh behavior when URLs expire
   - Test session-specific access controls

3. **Security Tests**:
   - Attempt to access images from different sessions
   - Verify URL expiration behavior
   - Test behavior with invalid or expired session cookies

## Migration Plan

1. **Stage 1: Implement Backend Changes**

   - Update storage service with signed URL functionality
   - Update image service to use signed URLs
   - Add URL refresh endpoint
   - Update response models to include expiration information

2. **Stage 2: Implement Frontend Changes**

   - Create image URL service with caching and refresh logic
   - Update image components to use the new service
   - Test with existing images

3. **Stage 3: Update Supabase Bucket Policies**
   - Update storage bucket policies to require Cookie header
   - Verify existing functionality continues to work

## Risk Assessment

1. **Performance Impact**

   - Risk: Additional URL refresh requests might impact performance
   - Mitigation: Implement caching and only refresh when needed

2. **User Experience**

   - Risk: Users might experience image loading issues during long sessions
   - Mitigation: Implement automatic URL refreshing before expiration

3. **Implementation Complexity**

   - Risk: Changes might introduce bugs in the image loading flow
   - Mitigation: Thorough testing and gradual deployment

4. **Backward Compatibility**
   - Risk: Existing stored image URLs might break
   - Mitigation: Update database records to use storage paths instead of full URLs

## Conclusion

Implementing signed URLs with short expiration provides a good balance of security and ease of implementation for the Concept Visualizer application. This approach maintains the current session-based, no-registration model while significantly improving security and preventing unauthorized access to user-generated images.

The implementation requires moderate changes to the backend and frontend but doesn't fundamentally change the application architecture. This makes it a practical choice for improving security in the near term.

In the future, if the application requires even stronger security, the other options (RLS with session authentication or server-side proxy) could be considered as part of a larger authentication system overhaul.
